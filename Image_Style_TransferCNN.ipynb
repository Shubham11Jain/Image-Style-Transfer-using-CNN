{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import major libraries that can be useful while implementing the below model\n",
    "import PIL.Image as Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "#import keras for CNN model\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import L-BFGS Algorithm library\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "#size of input images and output images\n",
    "IMAGE_WIDTH = 500\n",
    "IMAGE_HEIGHT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined paths which can be used for saving the images as external\n",
    "japanese_garder_image_path = \"input.png\"\n",
    "picasso_image_path = \"style.png\"\n",
    "output_image_path = \"output.png\"\n",
    "combined_image_path = \"combined.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining target image\n",
    "japanese_garden_image_path = \"https://raw.githubusercontent.com/myelinfoundry-2019/challenge/master/japanese_garden.jpg\"\n",
    "\n",
    "#Input visualization\n",
    "input_image = Image.open(BytesIO(requests.get(japanese_garden_image_path).content))\n",
    "input_image = input_image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "input_image.save(japanese_garden_image_path)\n",
    "input_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining style Image\n",
    "picasso_image_path = \"https://raw.githubusercontent.com/myelinfoundry-2019/challenge/master/picasso_selfportrait.jpg\"\n",
    "\n",
    "#Style visualization\n",
    "style_image = Image.open(BytesIO(requests.get(picasso_image_path).content))\n",
    "style_image = style_image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "style_image.save(picasso_image_path)\n",
    "style_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization and reshaping from RGB to BGR\n",
    "IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n",
    "input_image_array = np.asarray(input_image, dtype=\"float32\")\n",
    "input_image_array = np.expand_dims(input_image_array, axis=0)\n",
    "input_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "input_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "input_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "input_image_array = input_image_array[:, :, :, ::-1]\n",
    "\n",
    "style_image_array = np.asarray(style_image, dtype=\"float32\")\n",
    "style_image_array = np.expand_dims(style_image_array, axis=0)\n",
    "style_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "style_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "style_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "style_image_array = style_image_array[:, :, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "input_image = backend.variable(input_image_array)\n",
    "style_image = backend.variable(style_image_array)\n",
    "combination_image = backend.placeholder()\n",
    "\n",
    "input_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\n",
    "model = VGG16(input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEFINING LOSS FUNCTION \"\"\"\n",
    "\n",
    "#CONTENT LOSS \n",
    "def content_loss(content, combination):\n",
    "    return backend.sum(backend.square(combination - content))\n",
    "\n",
    "layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "CONTENT_WEIGHT = 0.02\n",
    "\n",
    "content_layer = \"block2_conv2\"\n",
    "layer_features = layers[content_layer]\n",
    "content_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "loss = backend.variable(0.)\n",
    "loss += CONTENT_WEIGHT * content_loss(content_image_features,\n",
    "                                      combination_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STYLE LOSS\n",
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram\n",
    "\n",
    "CHANNELS = 3\n",
    "def compute_style_loss(style, combination):\n",
    "    style = gram_matrix(style)\n",
    "    combination = gram_matrix(combination)\n",
    "    size = IMAGE_WIDTH*IMAGE_HEIGHT\n",
    "    return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n",
    "\n",
    "style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n",
    "STYLE_WEIGHT = 4.5\n",
    "for layer_name in style_layers:\n",
    "    layer_features = layers[layer_name]\n",
    "    style_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    style_loss = compute_style_loss(style_features, combination_features)\n",
    "    loss += (STYLE_WEIGHT / len(style_layers)) * style_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Variation LOSS\n",
    "TOTAL_VARIATION_WEIGHT = 0.995\n",
    "TOTAL_VARIATION_LOSS_FACTOR = 1.25\n",
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n",
    "    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n",
    "\n",
    "loss += TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization on each iteration to reduce or minimize the loss\n",
    "outputs = [loss]\n",
    "outputs += backend.gradients(loss, combination_image)\n",
    "\n",
    "def evaluate_loss_and_gradients(x):\n",
    "    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "    outs = backend.function([combination_image], outputs)([x])\n",
    "    loss = outs[0]\n",
    "    gradients = outs[1].flatten().astype(\"float64\")\n",
    "    return loss, gradients\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def loss(self, x):\n",
    "        loss, gradients = evaluate_loss_and_gradients(x)\n",
    "        self._gradients = gradients\n",
    "        return loss\n",
    "\n",
    "    def gradients(self, x):\n",
    "        return self._gradients\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS\n",
    "x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n",
    "\n",
    "\"\"\" Defining iterations, more the number of iterations, more will be the image style transfer.\n",
    "    For the GPU setting and due to time constraint, the iteration we are providing here is 10,\n",
    "    but you are allowed to change the number of iteration according to your GPU power. \"\"\"\n",
    "    \n",
    "ITERATIONS = 10\n",
    "for i in range(ITERATIONS):\n",
    "    x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n",
    "    print(\"Iteration %d completed with loss %d\" % (i, loss))\n",
    "\n",
    "x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "x = x[:, :, ::-1]\n",
    "x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n",
    "x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n",
    "x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n",
    "x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "output_image = Image.fromarray(x)\n",
    "output_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing combined results\n",
    "\"\"\" It will show the combined images of input image, style image and the output image\n",
    "            (the images that are saved as external) \"\"\"\n",
    "\n",
    "combined_image = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\n",
    "x_offset = 0\n",
    "for image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n",
    "    combined_image.paste(image, (x_offset, 0))\n",
    "    x_offset += IMAGE_WIDTH\n",
    "combined.save(combined_image_path)\n",
    "combined_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
